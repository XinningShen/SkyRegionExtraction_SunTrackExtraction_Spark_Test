import cv2
import numpy as np
from matplotlib.pyplot import *
from datetime import timedelta
from scipy.optimize import fmin
from scipy.optimize import fsolve

HEIGHT = 640
WIDTH = 640


def extract_image(imgfile_imgbytes):
    """ 
    Retrieve image and its file name from hadoop sequence file.

    Arg: 
        imgfile_imgbytes: binary key-value image file

    Return:
        tuple of image_file_name and image
    """
    imgfilename, imgbytes = imgfile_imgbytes
    nparr = np.fromstring(buffer(imgbytes), np.uint8)
    img = cv2.imdecode(nparr, 1)
    return (imgfilename, img)


def cannyDetect(img):
    """
    Detect Canny Edge for a single image.
    Mark 1 if pixel is detected as canny edge, else 0

    Arg:
        img: color image

    Return:
        dst: binary image after canny edge detection
    """
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    gray_bilateralFilter = cv2.bilateralFilter(gray, 5, 50, 50)
    dst = cv2.Canny(gray_bilateralFilter, 100, 200)
    dst[dst < 127] = 0
    dst[dst >= 127] = 1
    return dst


def colorDetect(img):
    """
    Mark a pixel sky/non-sky according to rgb criteria

    Arg:
        img: color image

    Return:
        binaryPic: binary image after rgb color detection
    """
    binaryPic = np.zeros((HEIGHT, WIDTH), np.uint8)
    for x in range(0, WIDTH):
        for y in range(0, HEIGHT):
            b = img.item(y, x, 0)
            g = img.item(y, x, 1)
            r = img.item(y, x, 2)
            criterion_1 = (b > 120 and g > 100 and r < 100 and (g - r) > 20)
            criterion_2 = (b > 100 and g > 100 and r > 100)
            criterion_3 = (b > 100 and g < 100 and r < 100 and (g - r) > 20)
            criterion_4 = (b < 100 and g < 100 and r < 100 and (b - g) > 20 and (g - r) > 20)
            if criterion_1 or criterion_2 or criterion_3 or criterion_4:
                binaryPic[y, x] = 1
            else:
                binaryPic[y, x] = 0
    return binaryPic


def checkSkyRegion(img):
    """
    Detect Sky Region of a single image using canny edge and rgb color methods

    Arg:
        img: color image to be detected

    Return:
        currentColorPic: Binary image after rgb color detection
        currentCannyPic: Binary image after canny edge detection
        1: counter, used for counting total number of images (faster than count() in spark)
    """
    currentCannyPic = np.zeros((HEIGHT, WIDTH), np.uint8)
    currentColorPic = np.zeros((HEIGHT, WIDTH), np.uint8)
    currentCannyPic = cannyDetect(img)
    currentColorPic = colorDetect(img)
    return (currentColorPic, currentCannyPic, 1)


def getSkyRegionMask(colorCountImg, edgeCountImg, color_threshold, edge_threshold):
    """
    Get Sky Region Mask after rgb color detection and canny edge detection.

    Args:
        colorCountImg: each pixel represents number of times that it is marked as sky region using rgb color method.
        edgeCountImg: each pixel represents number of times that it is marked as sky region using canny edge detection method.
        color_threshold: threshold that pixel should be marked as sky region using rgb color method.
        edge_threshold: threshold that pixel should be marked as sky region using canny edge detection method.
    Returns:
        sky_region: generated sky region mask using all-day image-stream.
    """
    sky_region = np.zeros((HEIGHT, WIDTH), np.uint8)
    for x in range(0, WIDTH):
        for y in range(0, HEIGHT):
            if colorCountImg[y, x] >= color_threshold and edgeCountImg[y, x] < edge_threshold:
                sky_region[y, x] = 255
            else:
                sky_region[y, x] = 0
    return sky_region


def markDisjointSkyRegion(sky_region, kernel):
    """
    Mark three largest disjoint area if several contour area detected

    Args:
        sky_region: sky region mask that generated by rgb and canny
        kernel: used for image erosion

    Returns:
        mask: sky region mask if several contour area detected
        cnts_new: new contours which have been marked
    """
    sky_region = cv2.erode(sky_region, kernel, iterations=1)

    mask = np.zeros(sky_region.shape[:2], np.uint8)

    (cnts, _) = cv2.findContours(
        sky_region.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    cnts = sorted(cnts, key=cv2.contourArea, reverse=True)[:3]

    full_size = HEIGHT * WIDTH
    cnts_new = []

    index = 0
    flag = False

    for index in range(0, len(cnts)):
        if float(cv2.contourArea(cnts[index])) < float(full_size / 20):
            flag = True
            break

    if flag:
        cnts_new = cnts[:index]
    else:
        cnts_new = cnts

    for mask_id in range(0, len(cnts_new)):
        cv2.drawContours(mask, cnts, mask_id, (mask_id + 1) * 80, -1)

    return mask, cnts_new


def get_R_Minus_B_Value(img, mask):
    """
    Calculate (r-b) value of each contour area

    Args:
        img: original image in each spark rdd element
        mask: sky region mask
    Returns:
        tuples: (id, (r-b) of each contour area)
    """
    contour0 = 0
    contour1 = 0
    contour2 = 0
    for x in range(0, HEIGHT):
        for y in range(0, WIDTH):
            grey_level = mask[x, y] / 80
            b = np.int16(img.item(x, y, 0))
            g = np.int16(img.item(x, y, 1))
            r = np.int16(img.item(x, y, 2))
            if grey_level == 1:
                contour0 += np.absolute(r - b)
            elif grey_level == 2:
                contour1 += np.absolute(r - b)
            elif grey_level == 3:
                contour2 += np.absolute(r - b)
    return (0, contour0), (1, contour1), (2, contour2)


def disjointRegionProcess(coef_list, contour_num, mask):
    """
    Calculate correlation coefficient value of cach contour area. If correlation coefficient is larger than 0.3 compared to largest area, mark area as sky region.

    Args:
        coef_list: (r-b) value of each contour area
        contour_num: number of contours
        mask: sky region mask
    """
    judge_result = [False] * contour_num
    judge_result[0] = True
    temp_list = []
    for i in range(1, contour_num):
        temp_list.append(coef_list[0][1])
        temp_list.append(coef_list[1][1])
        cc_matrix = np.corrcoef(temp_list)
        if cc_matrix[0, 1] >= 0.3:
            judge_result[i] = True

    for x in range(0, HEIGHT):
        for y in range(0, WIDTH):
            grey_level = mask[x, y] / 80
            if grey_level == 1:
                mask[x, y] = 255
            elif grey_level == 2 and judge_result[1] == False:
                mask[x, y] = 0
            elif grey_level == 2 and judge_result[1] == True:
                mask[x, y] = 255
            elif grey_level == 3 and judge_result[2] == False:
                mask[x, y] = 0
            elif grey_level == 3 and judge_result[2] == True:
                mask[x, y] = 255


def generateFinalSkyRegion(mask, kernel, contour_num):
    """
    Generate Final Sky Region with disjoint sky region.

    Args:
        mask: sky region mask
        kernel: kernel for dilate sky region
        contour_num: number of contours

    Returns:
        final_mask: final sky region mask
    """
    final = cv2.dilate(mask, kernel, iterations=1) 
    final_mask = np.zeros(final.shape[:2], np.uint8)
    (cnts2, _) = cv2.findContours(
        final, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    cnts2 = sorted(cnts2, key=cv2.contourArea, reverse=True)[:contour_num]
    cv2.drawContours(final_mask, cnts2, -1, 255, -1)
    return final_mask


def findMatchingFilenameBetweenTwoDay(d1, d2, d3):
    """
    Find images within time frame of two days. E.g 2015-09-01-10-00-30.jpg matches with 2015-09-02-10-01-00.jpg with 120 seconds time frame

    Args:
        d1: Day 1
        d2: Day 2
        d3: Day 3

    Returns:
        l1: matching list of day 1 against day 2
        l2_1: matching list of day 2 against day 1
        l2_3: matching list of day 2 against day 3
        l3: matching list of day 3 against day 2
    """
    pos_1 = 0
    pos_3 = 0
    l1 = []
    l2_1 = []
    l2_3 = []
    l3 = []

    for i in range(len(d2)):
        img_base_d2_filename = d2[i]
        img_base_d2_filename_timeformat = convertDateTimeFormat(img_base_d2_filename)
        match_1, pos_1 = getImageListInTimeFrame(d1, img_base_d2_filename_timeformat, start_pos=pos_1)
        match_3, pos_3 = getImageListInTimeFrame(d3, img_base_d2_filename_timeformat, start_pos=pos_3)

        if match_1 is not None:
            l1.append(match_1)
            l2_1.append(img_base_d2_filename)
        if match_3 is not None:
            l3.append(match_3)
            l2_3.append(img_base_d2_filename)
    return l1, l2_1, l2_3, l3



def convertDateTimeFormat(file_name):
    """
    Convert image file name to date time format
    """
    date_time = timedelta(hours=int(
        file_name[-12:-10]), minutes=int(file_name[-9:-7]), seconds=int(file_name[-6:-4]))
    return date_time


def getImageListInTimeFrame(imglib, base_time, time_frame=120, start_pos=0):
    """
    Get matching image from library based on base_time

    Args:
        imglib: image library for matching
        base_time: compared base time
        time_frame: default 120 seconds
        start_pos: start position of list for searching

    Returns:
        match: matching image file name
        start_pos: current stopped searching position
    """
    match = None

    if start_pos >= len(imglib):
        return None, start_pos

    for index in range(start_pos, len(imglib)):
        img_current = imglib[index]
        current_time = convertDateTimeFormat(img_current)
        if current_time < base_time and (base_time - current_time).total_seconds() > time_frame:
            continue
        elif current_time >= base_time and (current_time - base_time).total_seconds() > time_frame:
            start_pos = index
            break
        else:
            match = img_current
            start_pos = index + 1
            break
    return match, start_pos


def intersectionDetect(t1, t2):
    """
    Check whether two circle has intersection
    """
    mask_1 = np.zeros((HEIGHT, WIDTH), np.uint8)
    mask_2 = np.zeros((HEIGHT, WIDTH), np.uint8)

    cv2.circle(mask_1, t1[0], t1[1], 255, -1)
    cv2.circle(mask_2, t2[0], t2[1], 255, -1)

    intersection = cv2.bitwise_and(mask_1, mask_2)
    (cnt, _) = cv2.findContours(intersection, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    cnt = sorted(cnt, key=cv2.contourArea, reverse=True)[:1]
    if len(cnt) > 0:
        intersection_area = cv2.contourArea(cnt[0])
        if intersection_area > 0:
            return True
        else:
            return False

    return False


def getCentroidList(sun_orbit_list):
    centroid_list = []
    for i in sun_orbit_list:
        centroid_list.append(i[0][0])
        centroid_list.append(i[1][0])
    return centroid_list


matrix = None

def func(theta):
    """
    fmin search optimized function

    param: theta
    optimized param: residule of numpy.polyfit
    """
    global matrix
    cos_theta = np.cos(theta)
    sin_theta = np.sin(theta)
    Rmat = np.reshape(np.array([cos_theta, -sin_theta, sin_theta, cos_theta]), (2, 2))
    centroid_rotate = np.dot(Rmat, matrix)
    coeffs, res, _, _, _ = np.polyfit(centroid_rotate[0,:], centroid_rotate[1,:], 2, full=True)
    return res


def getCoeff(theta, centroid):
    """
    Get rotated optimized coefficient

    Args:
        theta: Rotation angular
        centroid: centroid list that needs to be rotated
    Return:
        coeffs: coefficient based on rotated centroid list
    """
    cos_theta = np.cos(theta)
    sin_theta = np.sin(theta)
    Rmat = np.reshape(np.array([cos_theta, -sin_theta, sin_theta, cos_theta]), (2, 2))
    centroid_rotate = np.dot(Rmat, centroid)
    coeffs, res, _, _, _ = np.polyfit(centroid_rotate[0,:], centroid_rotate[1,:], 2, full=True)
    return coeffs


def rotateClockWise(theta, x, y):
    """
    Clockwise rotate points according to the theta
    """
    cos_theta = np.cos(theta)
    sin_theta = np.sin(theta)
    Rmat = np.reshape(np.array([cos_theta, -sin_theta, sin_theta, cos_theta]), (2, 2))
    plot_point = np.array(zip(x, y))
    plot_point = np.transpose(plot_point)
    result = np.dot(np.linalg.inv(Rmat), plot_point)
    return result[0, :], result[1, :]


def generalParabola(centroid):
    """
    Generate sun track to general parabola.

    Arg:
        centroid: centroid list.

    Returns:
        theta: optimal rotation theta
        coeffs: quadratic formula coefficients.
    """
    global matrix
    x, y = zip(*centroid)
    y = tuple(HEIGHT - i for i in y)
    Centroid = zip(x, y)
    Centroid = np.transpose(np.asarray(Centroid))
    matrix = Centroid.copy()
    # theta = fmin(func, x0=0.79, args=(Centroid,))
    theta = fmin(func, x0=0.79)
    coeffs = getCoeff(theta, Centroid)
    print 'optimized coefficient = ', coeffs
    polynomial = np.poly1d(coeffs)
    xs_1 = np.arange(-10000, 10000, 0.5)
    ys_1 = polynomial(xs_1)
    xs_2, ys_2 = rotateClockWise(theta, xs_1, ys_1)
    plot(x, y, 'o')
    plot(xs_2, ys_2, '.r')
    axis([0, WIDTH, 0, HEIGHT])
    ylabel('y')
    xlabel('x')
    title('General Paraloba Fitting')
    show()
    return theta, coeffs

def sunDetect(img, mask):
    """
    Detect sun in an image using hsv channel.

    Args:
        img: color image to be detected
        mask: sky region mask

    Return:
        (centroid of circle, radius of circle)
    """
    img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)

    h_channel = img_hsv[:, :, 0]
    h_channel[h_channel <= 10] = 0
    h_channel[h_channel > 10] = 255
    h_channel = (255 - h_channel)

    h_channel = cv2.bitwise_and(mask, h_channel)

    kernel = np.ones((3, 3), np.uint8)
    h_channel = cv2.erode(h_channel, kernel, iterations=1)

    mask_h = np.zeros(h_channel.shape[:2], np.uint8)

    (cnts_h, _) = cv2.findContours(
        h_channel, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    cnts_h = sorted(cnts_h, key=cv2.contourArea, reverse=True)[:1]

    cv2.drawContours(mask_h, cnts_h, -1, 255, -1)

    mask_h = cv2.dilate(mask_h, kernel, iterations=1)

    (cnts_h, _) = cv2.findContours(
        mask_h, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    cnts_h = sorted(cnts_h, key=cv2.contourArea, reverse=True)[:1]

    cv2.drawContours(mask_h, cnts_h, -1, 255, -1)

    mask_h = cv2.medianBlur(mask_h, 15)

    if len(cnts_h) > 0:
        (x_h, y_h), radius_h = cv2.minEnclosingCircle(cnts_h[0])
        center_h = (int(x_h), int(y_h))
        radius_h = int(radius_h)

        mask_test_h = np.zeros((HEIGHT, WIDTH), np.uint8)
        cv2.circle(mask_test_h, center_h, radius_h, 255, -1)
        mask_test_h = cv2.bitwise_and(mask, mask_test_h)
        (cnts_test_h, _) = cv2.findContours(
            mask_test_h.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        cnts_test_h = sorted(cnts_test_h, key=cv2.contourArea, reverse=True)[:1]
        cv2.drawContours(img, cnts_test_h, -1, 255, 3)

        contour_area = cv2.contourArea(cnts_h[0])
        enclosing_area = cv2.contourArea(cnts_test_h[0])
        percentage = contour_area / enclosing_area

        if radius_h >= 15 and radius_h <= 100 and percentage >= 0.5:
            return (center_h, radius_h)

    return None
